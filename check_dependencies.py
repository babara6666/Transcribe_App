#!/usr/bin/env python3
"""
å®Œæ•´çš„ä¾è³´æª¢æŸ¥è…³æœ¬
æª¢æŸ¥ Pythonã€PyTorchã€CUDA åŠæ‰€æœ‰å¥—ä»¶çš„å…¼å®¹æ€§
"""

import sys
import subprocess
from pathlib import Path

def print_section(title):
    """æ‰“å°åˆ†éš”ç·šå’Œæ¨™é¡Œ"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)

def check_python_version():
    """æª¢æŸ¥ Python ç‰ˆæœ¬"""
    print_section("1ï¸âƒ£  Python ç‰ˆæœ¬æª¢æŸ¥")
    version = sys.version_info
    print(f"Python ç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    
    if version.major == 3 and version.minor == 10:
        print("âœ… Python 3.10.x - æ¨è–¦ç‰ˆæœ¬")
    elif version.major == 3 and version.minor == 11:
        print("âš ï¸  Python 3.11 - å¯èƒ½æœ‰éŸ³è¨Šåº«å…¼å®¹æ€§å•é¡Œ")
    elif version.major == 3 and version.minor < 10:
        print("âŒ Python ç‰ˆæœ¬éèˆŠï¼Œå»ºè­°å‡ç´šåˆ° 3.10.x")
    else:
        print("âš ï¸  æœªæ¸¬è©¦çš„ Python ç‰ˆæœ¬")

def check_pytorch():
    """æª¢æŸ¥ PyTorch å®‰è£å’Œ CUDA"""
    print_section("2ï¸âƒ£  PyTorch å’Œ CUDA æª¢æŸ¥")
    
    try:
        import torch
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        
        # æª¢æŸ¥ CUDA
        cuda_available = torch.cuda.is_available()
        print(f"CUDA å¯ç”¨: {cuda_available}")
        
        if cuda_available:
            print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPU åç¨±: {torch.cuda.get_device_name(0)}")
            print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")
            
            # æª¢æŸ¥æ¨è–¦ç‰ˆæœ¬
            if torch.__version__.startswith("2.1.2"):
                print("âœ… PyTorch 2.1.2 - éŸ³è¨Šè™•ç†æ¨è–¦ç‰ˆæœ¬")
            elif torch.__version__.startswith("2.5"):
                print("âš ï¸  PyTorch 2.5.x - å¯ç”¨ä½† 2.1.2 æ›´ç©©å®š")
            elif torch.__version__.startswith("2.6") or torch.__version__.startswith("2.7"):
                print("âš ï¸  PyTorch 2.6+ - å¯èƒ½æœ‰ omegaconf å…¼å®¹æ€§å•é¡Œ")
            else:
                print(f"â„¹ï¸  PyTorch {torch.__version__}")
        else:
            print("âš ï¸  æœªæª¢æ¸¬åˆ° CUDAï¼Œå°‡ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¼ƒæ…¢ï¼‰")
            
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£")

def check_torchaudio():
    """æª¢æŸ¥ Torchaudio"""
    print_section("3ï¸âƒ£  Torchaudio æª¢æŸ¥")
    
    try:
        import torchaudio
        import torch
        
        print(f"Torchaudio ç‰ˆæœ¬: {torchaudio.__version__}")
        
        # æª¢æŸ¥ç‰ˆæœ¬æ˜¯å¦åŒ¹é…
        torch_version = torch.__version__.split('+')[0]
        torchaudio_version = torchaudio.__version__.split('+')[0]
        
        if torch_version == torchaudio_version:
            print(f"âœ… ç‰ˆæœ¬åŒ¹é… (éƒ½æ˜¯ {torch_version})")
        else:
            print(f"âš ï¸  ç‰ˆæœ¬ä¸åŒ¹é…! PyTorch: {torch_version}, Torchaudio: {torchaudio_version}")
            
    except ImportError:
        print("âŒ Torchaudio æœªå®‰è£")

def check_core_packages():
    """æª¢æŸ¥æ ¸å¿ƒå¥—ä»¶"""
    print_section("4ï¸âƒ£  æ ¸å¿ƒå¥—ä»¶æª¢æŸ¥")
    
    packages = {
        "whisperx": "3.1.1",
        "pyannote.audio": "3.1.1",
        "faster_whisper": "1.0.0+",
        "ctranslate2": None,
        "transformers": "4.30.0+",
        "deep_translator": "1.11.4+",
        "python-dotenv": "1.0.0+",
    }
    
    for package_name, expected in packages.items():
        try:
            if package_name == "python-dotenv":
                import dotenv
                module = dotenv
                display_name = "python-dotenv"
            elif package_name == "pyannote.audio":
                import pyannote.audio
                module = pyannote.audio
                display_name = "pyannote.audio"
            elif package_name == "faster_whisper":
                import faster_whisper
                module = faster_whisper
                display_name = "faster_whisper"
            elif package_name == "deep_translator":
                import deep_translator
                module = deep_translator
                display_name = "deep_translator"
            else:
                module = __import__(package_name)
                display_name = package_name
            
            version = getattr(module, "__version__", "æœªçŸ¥")
            
            if expected:
                print(f"âœ… {display_name}: {version} (æœŸæœ›: {expected})")
            else:
                print(f"âœ… {display_name}: {version}")
                
        except ImportError as e:
            print(f"âŒ {package_name}: æœªå®‰è£ ({e})")

def check_pip_dependencies():
    """ä½¿ç”¨ pip check æª¢æŸ¥ä¾è³´è¡çª"""
    print_section("5ï¸âƒ£  Pip ä¾è³´è¡çªæª¢æŸ¥")
    
    try:
        result = subprocess.run(
            ["pip", "check"],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='ignore'
        )
        
        if result.returncode == 0:
            print("âœ… æ²’æœ‰æª¢æ¸¬åˆ°ä¾è³´è¡çª")
        else:
            print("âš ï¸  æª¢æ¸¬åˆ°ä»¥ä¸‹ä¾è³´å•é¡Œ:")
            print(result.stdout)
            
    except Exception as e:
        print(f"âŒ ç„¡æ³•åŸ·è¡Œ pip check: {e}")

def test_imports():
    """æ¸¬è©¦é—œéµå°å…¥"""
    print_section("6ï¸âƒ£  å¯¦éš›å°å…¥æ¸¬è©¦")
    
    test_cases = [
        ("torch", "import torch"),
        ("torchaudio", "import torchaudio"),
        ("whisperx", "import whisperx"),
        ("pyannote.audio", "import pyannote.audio"),
        ("faster_whisper", "import faster_whisper"),
        ("deep_translator", "from deep_translator import GoogleTranslator"),
        ("dotenv", "from dotenv import load_dotenv"),
    ]
    
    for name, import_stmt in test_cases:
        try:
            exec(import_stmt)
            print(f"âœ… {name} - å°å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {name} - å°å…¥å¤±æ•—: {e}")

def test_cuda_functionality():
    """æ¸¬è©¦ CUDA åŠŸèƒ½"""
    print_section("7ï¸âƒ£  CUDA åŠŸèƒ½æ¸¬è©¦")
    
    try:
        import torch
        
        if not torch.cuda.is_available():
            print("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œè·³éæ¸¬è©¦")
            return
        
        # æ¸¬è©¦å¼µé‡é‹ç®—
        x = torch.randn(3, 3).cuda()
        y = torch.randn(3, 3).cuda()
        z = x @ y
        
        print("âœ… CUDA å¼µé‡é‹ç®—æ­£å¸¸")
        print(f"   æ¸¬è©¦å¼µé‡å½¢ç‹€: {z.shape}")
        print(f"   GPU è¨˜æ†¶é«”ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        
    except Exception as e:
        print(f"âŒ CUDA åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {e}")

def show_installed_versions():
    """é¡¯ç¤ºå·²å®‰è£å¥—ä»¶ç‰ˆæœ¬"""
    print_section("8ï¸âƒ£  å·²å®‰è£å¥—ä»¶ç‰ˆæœ¬åˆ—è¡¨")
    
    try:
        result = subprocess.run(
            ["pip", "list"],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='ignore'
        )
        
        # ç¯©é¸é—œéµå¥—ä»¶
        keywords = [
            "torch", "whisper", "pyannote", "faster-whisper",
            "ctranslate2", "transformers", "deep-translator",
            "dotenv", "lightning", "numpy", "pandas"
        ]
        
        lines = result.stdout.split('\n')
        print("å¥—ä»¶åç¨±                    ç‰ˆæœ¬")
        print("-" * 50)
        
        for line in lines:
            if any(kw in line.lower() for kw in keywords):
                print(line)
                
    except Exception as e:
        print(f"âŒ ç„¡æ³•ç²å–å¥—ä»¶åˆ—è¡¨: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "ğŸ”" * 30)
    print("ä¾è³´å®Œæ•´æª¢æŸ¥å·¥å…· - Decord App")
    print("ğŸ”" * 30)
    
    check_python_version()
    check_pytorch()
    check_torchaudio()
    check_core_packages()
    check_pip_dependencies()
    test_imports()
    test_cuda_functionality()
    show_installed_versions()
    
    print("\n" + "=" * 60)
    print("  âœ… æª¢æŸ¥å®Œæˆ")
    print("=" * 60)
    print("\næç¤º: å¦‚æœç™¼ç¾å•é¡Œï¼Œè«‹åƒè€ƒ INSTALL.md å’Œ DEPENDENCIES.md")
    print()

if __name__ == "__main__":
    main()
